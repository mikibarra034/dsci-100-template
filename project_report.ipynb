{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90bd7003-a038-480f-a167-f5dff94b3205",
   "metadata": {},
   "source": [
    "# Visualizing the Effects of Cholesterol and Blood Pressure on Heart Disease\n",
    "\n",
    "*Mikel Ibarra Gallardo, Akshat Karla, Caitlin Lichimo, JunYuan Liu*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a7767c-f1ed-445b-b5aa-7e290257c123",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "   Heart disease is a major global cause of death that takes millions of lives per year. According to the CDC, there is one death in the US every 34 seconds due to heart disease. Not only is this unfortunate for those ⅕ people who suffer this demise, but it also costs billions of dollars in health care services. Heart disease data sets such as this one can be useful to predict factors that make certain demographics of people more susceptible for suffering from a heart disease, thus allowing the development of mitigation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eab3775-e469-498f-a0d8-6c6708e873fb",
   "metadata": {},
   "source": [
    "## Question: \n",
    "\n",
    "Are cholesterol and/or blood pressure good indicators of heart disease?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf69311-1efd-433b-a53f-cf7999c34fb6",
   "metadata": {},
   "source": [
    "## Preliminary Exploratory Data Analysis:\n",
    "\n",
    "We will be using the Heart Disease Data Set provided by UC Irvine. This data set describes heart condition information based on 303 individuals from different regions. This data is divided into 4 databases: Cleveland, Hungary, Switzerland, and the VA Long Beach, however we will only be utilizinng the Cleaveland data. The data set contains 76 attributes, but so far only 14 have been cited in literature:\n",
    "\n",
    "- Age: age in years\n",
    "- Sex: sex (1 = male; 0 = female)\n",
    "- Cp: chest pain type (value 1 = typical angina, value 2 = atypical angina, value 3 = non-anginal pain, value 4 = asymptomatic)\n",
    "- Trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "- Chol: serum cholesterol in mg/dl\n",
    "- Fbs: fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n",
    "- Restecg: resting electrocardiographic results (value 0 = normal, value 1 = having ST-T wave abnormality, value 2 = showing probably or definite left ventricular hypertrophy by Estes’ criteria\n",
    "- Thalach: maximum heart rate achieved\n",
    "- Exang: exercise induced angina (1 = yes; 0 = no)\n",
    "- Oldpeak: ST depression induced by exercise relative to rest\n",
    "- Slope: the slope of the peak exercise ST segment (value 1 = upsloping, value 2 = flat, value 3 = downsloping)\n",
    "- Ca: number of major vessels (0-3) colored by fluoroscopy\n",
    "- Thal: 3 = normal, 6 = fixed defect, 7 = reversible defect\n",
    "- Num: diagnosis of heart disease (angiographic disease status) (value 0 = <50% diameter narrowing, value 1 = > 50% diameter narrowing)\n",
    "\n",
    "For this project, we will be using the processed data from Cleaveland."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97ea2f-2117-47c1-8812-4bb74c6c0663",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "To start our preliminary analysis, we loaded the Heart Disease dataset from the original source on the web using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c956f-a4be-4982-baa1-3a7bf6c1f93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d039977c-f8f6-4c10-9617-033c8bd69eeb",
   "metadata": {},
   "source": [
    "Once downloaded, we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c5904-3cbf-4a78-b53e-0fca49c2bf7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1478d26-37ad-4c38-85f0-508a19a2e4ad",
   "metadata": {},
   "source": [
    "to read the data on Jupyter Hub. The columns from the original data did not have column names, so we wrangled the data to create column names using the read_delim function, storing this new data in a variable called df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981924c7-0a94-4d2b-8a93-4a79c76cdd00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72534ba7-6fae-474d-8113-9ebe238152be",
   "metadata": {},
   "source": [
    "Hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47fb49-b1a8-4dff-b0b7-b1b639ce3e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
